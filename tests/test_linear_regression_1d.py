
from __future__ import annotations

# SPDX-License-Identifier: MIT
# Copyright (c) 2025 Maurice Garcia

import unittest
import numpy as np
from pypnm.lib.signal_processing.linear_regression import LinearRegression1D

class TestLinearRegression1D(unittest.TestCase):
    def test_fit_with_autogenerated_x_perfect_line(self):
        y = [1, 3, 5, 7, 9]  # y = 2x + 1
        lr = LinearRegression1D(y)
        m, b = lr.params()
        self.assertAlmostEqual(m, 2.0, places=12)
        self.assertAlmostEqual(b, 1.0, places=12)
        self.assertAlmostEqual(lr.r2, 1.0, places=12)
        self.assertAlmostEqual(lr.rmse, 0.0, places=12)
        self.assertEqual(lr.n, 5)
        self.assertAlmostEqual(lr.to_list()[0], 2.0, places=12)
        d = lr.to_dict()
        self.assertSetEqual(set(d.keys()), {"slope", "intercept", "r2", "rmse", "n"})
        self.assertEqual(d["n"], float(lr.n))

    def test_fit_with_provided_x(self):
        x = [10, 20, 30, 40]
        y = [5, 15, 25, 35]  # y = x - 5
        lr = LinearRegression1D(y, x)
        m, b = lr.params()
        self.assertAlmostEqual(m, 1.0, places=12)
        self.assertAlmostEqual(b, -5.0, places=12)
        np.testing.assert_allclose(lr.predict([0, 100]), [-5.0, 95.0], rtol=1e-12, atol=1e-12)

    def test_nonfinite_filtering(self):
        x = [0, 1, 2, 3, 4, np.inf, 6]
        y = [1, 3, np.nan, 7, 9, 11, 13]  # valid: (0,1),(1,3),(3,7),(4,9),(6,13)
        lr = LinearRegression1D(y, x)
        m, b = lr.params()
        self.assertEqual(lr.n, 5)
        self.assertAlmostEqual(m, 2.0, places=12)
        self.assertAlmostEqual(b, 1.0, places=12)
        self.assertAlmostEqual(lr.r2, 1.0, places=12)

    def test_errors(self):
        with self.assertRaises(ValueError):
            LinearRegression1D([1, 2, 3], [0, 1])       # length mismatch
        with self.assertRaises(ValueError):
            LinearRegression1D([1, 2, 3], [0, np.nan, np.inf])  # too few finite
        with self.assertRaises(ValueError):
            LinearRegression1D([1, 2, 3, 4], [5, 5, 5, 5])      # zero variance

    def test_constant_y_edge_case(self):
        x = [0, 1, 2, 3, 4]
        y = [7, 7, 7, 7, 7]
        lr = LinearRegression1D(y, x)
        m, b = lr.params()
        self.assertAlmostEqual(m, 0.0, places=12)
        self.assertAlmostEqual(b, 7.0, places=12)
        self.assertAlmostEqual(lr.rmse, 0.0, places=12)
        self.assertAlmostEqual(lr.r2, 1.0, places=12)

    def test_predict_scalar_and_array(self):
        y = [1, 3, 5, 7, 9]  # y = 2x + 1
        lr = LinearRegression1D(y)
        p0 = lr.predict([0])
        self.assertEqual(np.ndim(p0), 0)
        self.assertAlmostEqual(float(np.asarray(p0)), 1.0, places=12)
        parr = np.asarray(lr.predict([0, 2, 4]))
        self.assertEqual(parr.shape, (3,))
        np.testing.assert_allclose(parr, [1.0, 5.0, 9.0], rtol=1e-12, atol=1e-12)

    def test_repr(self):
        y = [1, 2, 3]
        lr = LinearRegression1D(y)
        s = repr(lr)
        for token in ("LinearRegression1D", "slope=", "intercept=", "r2=", "rmse=", "n="):
            self.assertIn(token, s)


if __name__ == "__main__":
    unittest.main()
